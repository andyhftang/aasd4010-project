{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/andyhftang/aasd4010-project/main/model/stock_data.csv?token=GHSAT0AAAAAACS52BKUFG4KSGLB5IKDQJGOZSZARHA'\n",
        "data = pd.read_csv('stock_data.csv')\n"
      ],
      "metadata": {
        "id": "xCjemSCnggVr"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Data Preprocessing"
      ],
      "metadata": {
        "id": "osCJNgmJoOX-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Clean the text data\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    text = text.lower()\n",
        "    return text\n",
        "\n",
        "data['cleaned_text'] = data['Text'].apply(clean_text)\n",
        "\n",
        "# Tokenize the text\n",
        "tokenizer = Tokenizer(num_words=5000, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(data['cleaned_text'])\n",
        "sequences = tokenizer.texts_to_sequences(data['cleaned_text'])\n",
        "padded_sequences = pad_sequences(sequences, maxlen=50, padding='post')\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, data['Sentiment'], test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "2vgsmDE9gqDs"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Model Selection"
      ],
      "metadata": {
        "id": "A6XLHQzToQtI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=5000, output_dim=64, input_length=50),\n",
        "    Bidirectional(LSTM(64, dropout=0.2, return_sequences=True)),\n",
        "    Bidirectional(LSTM(32)),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JG_nwaFgo9ja",
        "outputId": "1d091934-af1e-4006-97ee-f93584fb895b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 50, 64)            320000    \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 50, 128)           66048     \n",
            " al)                                                             \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirecti  (None, 64)                41216     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 427329 (1.63 MB)\n",
            "Trainable params: 427329 (1.63 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Model Training"
      ],
      "metadata": {
        "id": "RLEoCh2msuSo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), batch_size=64)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8Xq6xW6oZ8x",
        "outputId": "ad940628-f984-492e-b534-0c1e614be38e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "73/73 [==============================] - 24s 201ms/step - loss: 0.5136 - accuracy: 0.0214 - val_loss: -0.1154 - val_accuracy: 0.2942\n",
            "Epoch 2/20\n",
            "73/73 [==============================] - 13s 174ms/step - loss: -1.5470 - accuracy: 0.4763 - val_loss: -1.4184 - val_accuracy: 0.4806\n",
            "Epoch 3/20\n",
            "73/73 [==============================] - 13s 174ms/step - loss: -3.6694 - accuracy: 0.5006 - val_loss: -2.4884 - val_accuracy: 0.4288\n",
            "Epoch 4/20\n",
            "73/73 [==============================] - 13s 172ms/step - loss: -5.9622 - accuracy: 0.5300 - val_loss: -3.1232 - val_accuracy: 0.5298\n",
            "Epoch 5/20\n",
            "73/73 [==============================] - 11s 144ms/step - loss: -7.8418 - accuracy: 0.5468 - val_loss: -3.9252 - val_accuracy: 0.4668\n",
            "Epoch 6/20\n",
            "73/73 [==============================] - 18s 247ms/step - loss: -8.7718 - accuracy: 0.5475 - val_loss: -4.8239 - val_accuracy: 0.4625\n",
            "Epoch 7/20\n",
            "73/73 [==============================] - 10s 141ms/step - loss: -10.4549 - accuracy: 0.5579 - val_loss: -4.7657 - val_accuracy: 0.4504\n",
            "Epoch 8/20\n",
            "73/73 [==============================] - 13s 173ms/step - loss: -11.9864 - accuracy: 0.5440 - val_loss: -6.1192 - val_accuracy: 0.4771\n",
            "Epoch 9/20\n",
            "73/73 [==============================] - 13s 174ms/step - loss: -14.1799 - accuracy: 0.5585 - val_loss: -7.0167 - val_accuracy: 0.4702\n",
            "Epoch 10/20\n",
            "73/73 [==============================] - 13s 174ms/step - loss: -15.6487 - accuracy: 0.5542 - val_loss: -6.6344 - val_accuracy: 0.4478\n",
            "Epoch 11/20\n",
            "73/73 [==============================] - 12s 170ms/step - loss: -15.6184 - accuracy: 0.5445 - val_loss: -6.4319 - val_accuracy: 0.3952\n",
            "Epoch 12/20\n",
            "73/73 [==============================] - 13s 174ms/step - loss: -14.4257 - accuracy: 0.4834 - val_loss: -8.2952 - val_accuracy: 0.4789\n",
            "Epoch 13/20\n",
            "73/73 [==============================] - 12s 166ms/step - loss: -19.2510 - accuracy: 0.5397 - val_loss: -9.2528 - val_accuracy: 0.3348\n",
            "Epoch 14/20\n",
            "73/73 [==============================] - 11s 144ms/step - loss: -21.1579 - accuracy: 0.5119 - val_loss: -10.4433 - val_accuracy: 0.3382\n",
            "Epoch 15/20\n",
            "73/73 [==============================] - 13s 175ms/step - loss: -24.1512 - accuracy: 0.5488 - val_loss: -9.9237 - val_accuracy: 0.4625\n",
            "Epoch 16/20\n",
            "73/73 [==============================] - 15s 213ms/step - loss: -26.3465 - accuracy: 0.5617 - val_loss: -10.3023 - val_accuracy: 0.4400\n",
            "Epoch 17/20\n",
            "73/73 [==============================] - 12s 167ms/step - loss: -29.2264 - accuracy: 0.5784 - val_loss: -12.3010 - val_accuracy: 0.4771\n",
            "Epoch 18/20\n",
            "73/73 [==============================] - 13s 174ms/step - loss: -31.6705 - accuracy: 0.5896 - val_loss: -12.9719 - val_accuracy: 0.4711\n",
            "Epoch 19/20\n",
            "73/73 [==============================] - 12s 163ms/step - loss: -33.7114 - accuracy: 0.5879 - val_loss: -14.2307 - val_accuracy: 0.4901\n",
            "Epoch 20/20\n",
            "73/73 [==============================] - 10s 141ms/step - loss: -35.5820 - accuracy: 0.5941 - val_loss: -14.3414 - val_accuracy: 0.4814\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Model Evaluation"
      ],
      "metadata": {
        "id": "YeBT2UeBsxL9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Loss: {loss}, Accuracy: {accuracy}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8Kv_z5mobUH",
        "outputId": "506bc2a2-a098-4cf5-d5cb-ecbdb86e8853"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "37/37 [==============================] - 1s 26ms/step - loss: -14.3414 - accuracy: 0.4814\n",
            "Loss: -14.341419219970703, Accuracy: 0.48144951462745667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Model Export"
      ],
      "metadata": {
        "id": "Z5spgDSlszPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save the model\n",
        "model.save('semantic_analysis_model.h5')\n",
        "\n",
        "# Save the Tokenizer\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBTQBalCocrM",
        "outputId": "ff7e4b02-46ea-4f71-c72d-0095385ebf92"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6: Prediction Script"
      ],
      "metadata": {
        "id": "yLDZFpAWs1PK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Load the trained model\n",
        "model = load_model('semantic_analysis_model.h5')\n",
        "\n",
        "# Load the Tokenizer\n",
        "with open('tokenizer.pickle', 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)\n",
        "\n",
        "# Function to predict text\n",
        "def predict_text(text):\n",
        "    cleaned_text = clean_text(text)\n",
        "    sequence = tokenizer.texts_to_sequences([cleaned_text])\n",
        "    padded_sequence = pad_sequences(sequence, maxlen=50, padding='post')\n",
        "    prediction = model.predict(padded_sequence)\n",
        "    return 'Positive' if prediction >= 0.5 else 'Negative'\n"
      ],
      "metadata": {
        "id": "mbv-_mSvod2F"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "new_text = \"Don't buy stock today!!\"\n",
        "prediction = predict_text(new_text)\n",
        "print(f'The sentiment of the news headline \"{new_text}\" is {prediction}.')\n",
        "\n",
        "\n",
        "# Example usage\n",
        "new_text = \"Today is the best day to buy stock!\"\n",
        "prediction = predict_text(new_text)\n",
        "print(f'The sentiment of the news headline \"{new_text}\" is {prediction}.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFXecCl2ykuI",
        "outputId": "3f6f4a6e-d868-4d50-907c-c5205bb06201"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "The sentiment of the news headline \"Don't buy stock today!!\" is Negative.\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "The sentiment of the news headline \"Today is the best day to buy stock!\" is Positive.\n"
          ]
        }
      ]
    }
  ]
}